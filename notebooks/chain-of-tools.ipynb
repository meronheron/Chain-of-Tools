{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe304b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:31.408071Z",
     "iopub.status.busy": "2025-06-12T23:42:31.407692Z",
     "iopub.status.idle": "2025-06-12T23:42:33.62841Z",
     "shell.execute_reply": "2025-06-12T23:42:33.627367Z"
    },
    "papermill": {
     "duration": 2.229358,
     "end_time": "2025-06-12T23:42:33.63048",
     "exception": false,
     "start_time": "2025-06-12T23:42:31.401122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2641e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:33.643543Z",
     "iopub.status.busy": "2025-06-12T23:42:33.643079Z",
     "iopub.status.idle": "2025-06-12T23:42:42.923079Z",
     "shell.execute_reply": "2025-06-12T23:42:42.921721Z"
    },
    "papermill": {
     "duration": 9.288153,
     "end_time": "2025-06-12T23:42:42.924969",
     "exception": false,
     "start_time": "2025-06-12T23:42:33.636816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f9c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:42.944361Z",
     "iopub.status.busy": "2025-06-12T23:42:42.944025Z",
     "iopub.status.idle": "2025-06-12T23:42:44.438977Z",
     "shell.execute_reply": "2025-06-12T23:42:44.437521Z"
    },
    "papermill": {
     "duration": 1.506928,
     "end_time": "2025-06-12T23:42:44.441042",
     "exception": false,
     "start_time": "2025-06-12T23:42:42.934114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/meronheron/Chain-of-Tools.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb58c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:44.46174Z",
     "iopub.status.busy": "2025-06-12T23:42:44.461372Z",
     "iopub.status.idle": "2025-06-12T23:42:44.587758Z",
     "shell.execute_reply": "2025-06-12T23:42:44.585866Z"
    },
    "papermill": {
     "duration": 0.139279,
     "end_time": "2025-06-12T23:42:44.589783",
     "exception": false,
     "start_time": "2025-06-12T23:42:44.450504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b48db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:45.902794Z",
     "iopub.status.busy": "2025-06-12T23:42:45.902382Z",
     "iopub.status.idle": "2025-06-12T23:42:46.026956Z",
     "shell.execute_reply": "2025-06-12T23:42:46.025752Z"
    },
    "papermill": {
     "duration": 0.137733,
     "end_time": "2025-06-12T23:42:46.028883",
     "exception": false,
     "start_time": "2025-06-12T23:42:45.89115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/Chain-of-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '/torch==2.2.1+cu118/d; /torchaudio==2.2.1+cu118/d; /torchvision==0.17.1+cu118/d' /kaggle/working/Chain-of-Tools/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bed85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.049764Z",
     "iopub.status.busy": "2025-06-12T23:42:46.049363Z",
     "iopub.status.idle": "2025-06-12T23:42:46.172322Z",
     "shell.execute_reply": "2025-06-12T23:42:46.171105Z"
    },
    "papermill": {
     "duration": 0.135463,
     "end_time": "2025-06-12T23:42:46.174523",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.03906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r /kaggle/working/Chain-of-Tools/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78486f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.194461Z",
     "iopub.status.busy": "2025-06-12T23:42:46.194084Z",
     "iopub.status.idle": "2025-06-12T23:42:46.344236Z",
     "shell.execute_reply": "2025-06-12T23:42:46.342902Z"
    },
    "papermill": {
     "duration": 0.162356,
     "end_time": "2025-06-12T23:42:46.346257",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.183901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torchvision==0.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e08214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.366702Z",
     "iopub.status.busy": "2025-06-12T23:42:46.366328Z",
     "iopub.status.idle": "2025-06-12T23:42:46.491882Z",
     "shell.execute_reply": "2025-06-12T23:42:46.490661Z"
    },
    "papermill": {
     "duration": 0.138148,
     "end_time": "2025-06-12T23:42:46.493568",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.35542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2fad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.513593Z",
     "iopub.status.busy": "2025-06-12T23:42:46.513245Z",
     "iopub.status.idle": "2025-06-12T23:42:46.636288Z",
     "shell.execute_reply": "2025-06-12T23:42:46.634546Z"
    },
    "papermill": {
     "duration": 0.135608,
     "end_time": "2025-06-12T23:42:46.638339",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.502731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep -E 'accelerate|beautifulsoup4|einops|huggingface-hub|numpy|safetensors|tokenizers|torchvision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639b25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.660492Z",
     "iopub.status.busy": "2025-06-12T23:42:46.659541Z",
     "iopub.status.idle": "2025-06-12T23:42:46.952926Z",
     "shell.execute_reply": "2025-06-12T23:42:46.951172Z"
    },
    "papermill": {
     "duration": 0.30642,
     "end_time": "2025-06-12T23:42:46.95522",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.6488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/Chain-of-Tools/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd1ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:46.976145Z",
     "iopub.status.busy": "2025-06-12T23:42:46.975775Z",
     "iopub.status.idle": "2025-06-12T23:42:47.100547Z",
     "shell.execute_reply": "2025-06-12T23:42:47.099149Z"
    },
    "papermill": {
     "duration": 0.137445,
     "end_time": "2025-06-12T23:42:47.102448",
     "exception": false,
     "start_time": "2025-06-12T23:42:46.965003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working/Chain-of-Tools/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e338b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:47.12277Z",
     "iopub.status.busy": "2025-06-12T23:42:47.12238Z",
     "iopub.status.idle": "2025-06-12T23:42:47.246491Z",
     "shell.execute_reply": "2025-06-12T23:42:47.24523Z"
    },
    "papermill": {
     "duration": 0.136548,
     "end_time": "2025-06-12T23:42:47.248474",
     "exception": false,
     "start_time": "2025-06-12T23:42:47.111926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/config\n",
    "!cp /kaggle/working/Chain-of-Tools/config/basic.yaml /kaggle/working/config/\n",
    "!mkdir -p /kaggle/working/my_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028f572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:42:47.269348Z",
     "iopub.status.busy": "2025-06-12T23:42:47.268997Z",
     "iopub.status.idle": "2025-06-12T23:46:28.973008Z",
     "shell.execute_reply": "2025-06-12T23:46:28.971248Z"
    },
    "papermill": {
     "duration": 221.7171,
     "end_time": "2025-06-12T23:46:28.975228",
     "exception": false,
     "start_time": "2025-06-12T23:42:47.258128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sed -i 's|checkpoint: ../PTM/Llama-2-7b-chat-hf|checkpoint: mistralai/Mistral-7B-Instruct-v0.2|' /kaggle/working/config/basic.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb022bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:46:29.162462Z",
     "iopub.status.busy": "2025-06-12T23:46:29.162009Z",
     "iopub.status.idle": "2025-06-12T23:49:29.222484Z",
     "shell.execute_reply": "2025-06-12T23:49:29.221146Z"
    },
    "papermill": {
     "duration": 180.15581,
     "end_time": "2025-06-12T23:49:29.22449",
     "exception": false,
     "start_time": "2025-06-12T23:46:29.06868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1762771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:49:33.416707Z",
     "iopub.status.busy": "2025-06-12T23:49:33.415459Z",
     "iopub.status.idle": "2025-06-12T23:49:46.415755Z",
     "shell.execute_reply": "2025-06-12T23:49:46.414404Z"
    },
    "papermill": {
     "duration": 13.208397,
     "end_time": "2025-06-12T23:49:46.418205",
     "exception": false,
     "start_time": "2025-06-12T23:49:33.209808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient; \n",
    "from huggingface_hub import login; \n",
    "\n",
    "login(token=UserSecretsClient().get_secret('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90b9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:49:46.769625Z",
     "iopub.status.busy": "2025-06-12T23:49:46.768567Z",
     "iopub.status.idle": "2025-06-12T23:49:46.893091Z",
     "shell.execute_reply": "2025-06-12T23:49:46.891503Z"
    },
    "papermill": {
     "duration": 0.297896,
     "end_time": "2025-06-12T23:49:46.895121",
     "exception": false,
     "start_time": "2025-06-12T23:49:46.597225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /kaggle/working/config/basic.yaml | grep checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c3792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:49:47.924381Z",
     "iopub.status.busy": "2025-06-12T23:49:47.923996Z",
     "iopub.status.idle": "2025-06-12T23:49:48.046833Z",
     "shell.execute_reply": "2025-06-12T23:49:48.045442Z"
    },
    "papermill": {
     "duration": 0.379713,
     "end_time": "2025-06-12T23:49:48.049093",
     "exception": false,
     "start_time": "2025-06-12T23:49:47.66938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls /kaggle/working\n",
    "!ls /kaggle/working/Chain-of-Tools/src/script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a894b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T23:49:48.868914Z",
     "iopub.status.busy": "2025-06-12T23:49:48.867922Z",
     "iopub.status.idle": "2025-06-12T23:49:54.174924Z",
     "shell.execute_reply": "2025-06-12T23:49:54.173282Z"
    },
    "papermill": {
     "duration": 5.481772,
     "end_time": "2025-06-12T23:49:54.176832",
     "exception": false,
     "start_time": "2025-06-12T23:49:48.69506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls Chain-of-Tools/src/script/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find /kaggle/working/Chain-of-Tools -name \"WillMindS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /kaggle/working/Chain-of-Tools/src/WillMindS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|checkpoint: ../PTM/Llama-2-7b-chat-hf|checkpoint: mistralai/Mistral-7B-Instruct-v0.2|' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's/half_quantized: True/half_quantized: False/' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's/train_batch: 4/train_batch: 2/' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's/train_batch: 8/train_batch: 2/' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's/gradient_accumulation_steps: 16/gradient_accumulation_steps: 32/' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's|meta-llama/Llama-2-7b-chat-hf|mistralai/Mistral-7B-Instruct-v0.2|' /kaggle/working/Chain-of-Tools/config/train_judge.yaml\n",
    "!sed -i 's/model_name: LLaMA/model_name: Mistral/' /kaggle/working/Chain-of-Tools/config/train_judge.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/working/Chain-of-Tools/config/train_judge.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers==4.41.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|from transformers import MistralTokenizer; self.tokenizer = MistralTokenizer.from_pretrained(self.config.checkpoint, use_fast=True)|from transformers import AutoTokenizer; self.tokenizer = AutoTokenizer.from_pretrained(self.config.checkpoint, use_fast=True, trust_remote_code=True)|' /kaggle/working/Chain-of-Tools/src/model.py\n",
    "!sed -i 's|from transformers import LlamaTokenizer; self.tokenizer = LlamaTokenizer.from_pretrained(self.config.checkpoint, use_fast=True)|from transformers import AutoTokenizer; self.tokenizer = AutoTokenizer.from_pretrained(self.config.checkpoint, use_fast=True, trust_remote_code=True)|' /kaggle/working/Chain-of-Tools/src/model.py\n",
    "!sed -i 's|self.tokenizer(tool_data, return_tensors=\"pt\", add_special_tokens=False)|self.tokenizer(tool_data, return_tensors=\"pt\")|' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|self.foundation_model = AutoModelForCausalLM.from_pretrained(self.config.checkpoint, device_map=\"auto\")|from transformers import BitsAndBytesConfig, AutoModelForCausalLM; import torch; quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16); self.foundation_model = AutoModelForCausalLM.from_pretrained(self.config.checkpoint, device_map=\"auto\", quantization_config=quantization_config); self.foundation_model.gradient_checkpointing_enable()|' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|.to(\"cuda:1\")|.to(\"cuda:0\")|' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|self.retriever_tool_selection = MLPLayer(self.hidden_size, self.intermediate_size, self.retrieval_size).to(\"cuda:0\")|self.retriever_tool_selection = MLPLayer(self.hidden_size, self.intermediate_size, self.retrieval_size).to(\"cuda:0\").to(torch.float16)|' /kaggle/working/Chain-of-Tools/src/model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i s|self.tool_judge = MLPLayer(self.hidden_size, self.intermediate_size, 3).to(\"cuda:0\")|self.tool_judge = MLPLayer(self.hidden_size, self.intermediate_size, 3).to(\"cuda:0\").to(torch.float16)|' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i 's|probs = self.tool_judge(hidden_states.to(next(self.tool_judge.parameters()).device))|self.tool_judge.to(dtype=torch.float16)\\n        device = next(self.tool_judge.parameters()).device\\n        probs = self.tool_judge(hidden_states.to(device=device, dtype=torch.float16))|' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '/def forward(self, x):/{n;s|.*down_proj = self.down_proj.*|        x = x.to(dtype=torch.float16)\\n        down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))|}' /kaggle/working/Chain-of-Tools/src/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/working/Chain-of-Tools/src/model.py | grep -A 5 \"def forward(self, x):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/working/Chain-of-Tools/src/train.py | grep -A 14 \"loss = F.binary_cross_entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress XLA warnings\n",
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_enable_cudnn_autotune=false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /kaggle/working/Chain-of-Tools/config/train_judge.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -R /kaggle/working/Chain-of-Tools/data/gsm8k_xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /kaggle/working/Chain-of-Tools/my_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/Chain-of-Tools && PYTHONPATH=/kaggle/working/Chain-of-Tools/src PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True python src/script/train_gsm8k_judge.py --config_file config/train_judge.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!cd /kaggle/working/Chain-of-Tools && PYTHONPATH=/kaggle/working/Chain-of-Tools/src python src/script/test_gsm8k.py --config_file config/test.yaml"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 553.167807,
   "end_time": "2025-06-12T23:51:39.443231",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T23:42:26.275424",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
